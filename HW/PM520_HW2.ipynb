{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YichenGuo82/Linear-Algebra-and-Learning-from-Data/blob/master/HW/PM520_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2. Maximum likelihood & Optimization Crash Course"
      ],
      "metadata": {
        "id": "SB19uPlEpw4u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k0RgUYaXfIWf",
        "outputId": "5e741445-371c-4900-9950-c56d05d78400",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lineax\n",
            "  Downloading lineax-0.1.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting equinox>=0.11.10 (from lineax)\n",
            "  Downloading equinox-0.13.4-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: jax>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from lineax) (0.7.2)\n",
            "Collecting jaxtyping>=0.2.24 (from lineax)\n",
            "  Downloading jaxtyping-0.3.7-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from lineax) (4.15.0)\n",
            "Collecting wadler-lindig>=0.1.0 (from equinox>=0.11.10->lineax)\n",
            "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: jaxlib<=0.7.2,>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from jax>=0.6.1->lineax) (0.7.2)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax>=0.6.1->lineax) (0.5.4)\n",
            "Requirement already satisfied: numpy>=2.0 in /usr/local/lib/python3.12/dist-packages (from jax>=0.6.1->lineax) (2.0.2)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax>=0.6.1->lineax) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax>=0.6.1->lineax) (1.16.3)\n",
            "Downloading lineax-0.1.0-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading equinox-0.13.4-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxtyping-0.3.7-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: wadler-lindig, jaxtyping, equinox, lineax\n",
            "Successfully installed equinox-0.13.4 jaxtyping-0.3.7 lineax-0.1.0 wadler-lindig-0.1.7\n"
          ]
        }
      ],
      "source": [
        "!pip install lineax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.numpy.linalg as jnpla\n",
        "import jax.scipy as jsp\n",
        "import jax.scipy.linalg as jspla"
      ],
      "metadata": {
        "id": "0aNnRcuZfTXi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Ordinary least squares (i.e. OLS)\n",
        "OLS is an approach to fit a linear regression model $$y = X \\beta + ɛ,$$\n",
        "such that $\\mathbb{E}[ɛ'ɛ]$ is minimized, where $\\mathbb{E}[ɛ_i]=0$ and\n",
        "$\\mathbb{V}[ɛ_i] = \\sigma^2$, for each $i=1,\\dotsc,n$.\n",
        "\n",
        "1.1 Derive the OLS solution $\\hat{\\beta}$ under the above objective. Show step by step.\n",
        "\n",
        "1.2 Re-write the objective using a likelihood formulation assuming $ɛ_i \\sim N(0, \\sigma^2)$, for each $i=1,\\dotsc,n$.\n",
        "\n",
        "1.3 Derive the OLS solution $\\hat{\\beta}_{MLE}$ using the above objective. Show step by step.\n",
        "\n",
        "1.4 Using [lineax](https://docs.kidger.site/lineax/), implement a solver for OLS."
      ],
      "metadata": {
        "id": "CtLu4_XIfaC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1\n",
        "Define the least squares objective\n",
        "$$\n",
        "S(\\beta) := \\|y - X\\beta\\|_2^2 = (y - X\\beta)^\\top (y - X\\beta).\n",
        "$$\n",
        "\n",
        "Expand:\n",
        "$$\n",
        "\\begin{align*}\n",
        "S(\\beta)\n",
        "&= (y - X\\beta)^\\top (y - X\\beta) \\\\\n",
        "&= y^\\top y - 2\\beta^\\top X^\\top y + \\beta^\\top X^\\top X \\beta.\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "Differentiate w.r.t. $\\beta$ and set to zero:\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\nabla_\\beta S(\\beta)\n",
        "&= -2X^\\top y + 2X^\\top X\\beta \\\\\n",
        "&= 0\n",
        "\\quad\\Longrightarrow\\quad\n",
        "X^\\top X \\hat\\beta = X^\\top y.\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "$$ \\begin{align*}\n",
        "\\hat{\\beta} = (X^\\top X)^{-1} X^\\top y\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "h50n_Xiz-xP5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2\n",
        "Assuming $\\varepsilon_i \\sim N(0, \\sigma^2)$, the model $y = X\\beta + \\varepsilon$ implies $y \\sim N(X\\beta, \\sigma^2 I)$. The log-likelihood function $\\ell(\\beta, \\sigma^2)$ is:\n",
        "\n",
        "$$\\ell(\\beta, \\sigma^2) = -\\frac{n}{2} \\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} (y - X\\beta)^\\top (y - X\\beta)$$"
      ],
      "metadata": {
        "id": "GC3-mi-QAYxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 MLE Solution\n",
        "To find the Maximum Likelihood Estimator $\\hat{\\beta}_{MLE}$, we maximize $\\ell(\\beta, \\sigma^2)$ with respect to $\\beta$.\n",
        "\n",
        "1. Maximizing $\\ell$ is equivalent to minimizing the negative term:\n",
        "   $$\\hat{\\beta}_{MLE} = \\arg\\min_\\beta (y - X\\beta)^\\top (y - X\\beta)$$\n",
        "2. Taking the derivative with respect to $\\beta$ yields:\n",
        "   $$\\nabla_\\beta \\ell = \\frac{1}{\\sigma^2}(X^\\top y - X^\\top X\\beta)$$\n",
        "3. Setting to zero results in:\n",
        "   $$X^\\top X \\hat{\\beta}_{MLE} = X^\\top y$$\n",
        "   $$\\hat{\\beta}_{MLE} = (X^\\top X)^{-1} X^\\top y$$"
      ],
      "metadata": {
        "id": "6cGJ3mo4AxYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lineax as lx\n",
        "\n",
        "from jax import Array\n",
        "from jax.typing import ArrayLike\n",
        "\n",
        "\n",
        "def solve_ols(y: ArrayLike, X: ArrayLike) -> Array:\n",
        "  \"\"\"\n",
        "  Solves ordinary least squares using lineax.\n",
        "\n",
        "  y: ArrayLike of observations\n",
        "  X: ArrayLike of covariates\n",
        "\n",
        "  returns: $hat{\\beta}$ for OLS\n",
        "  \"\"\"\n",
        "\n",
        "  Xop = lx.MatrixLinearOperator(X)\n",
        "\n",
        "  # minimize ||y - X beta||^2\n",
        "  sol = lx.linear_solve(\n",
        "      Xop,\n",
        "      y,\n",
        "      solver=lx.Normal(lx.CG(atol=1e-6, rtol=1e-6))\n",
        "  )\n",
        "  return sol.value"
      ],
      "metadata": {
        "id": "f4f3welGhtMg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Weighted least squares (i.e. WLS)\n",
        "WLS is an approach to fit a slightly more general linear model where, $$y = X \\beta + ɛ,$$ where $\\mathbb{E}[ɛ_i] = 0$ and $\\mathbb{V}[ɛ_i] = \\sigma^2_i$. We can model all variances jointly as $\\mathbb{V}[ɛ] = D$ where $D$ is a diagonal matrix such that $D_{ii} = \\sigma^2_i$.\n",
        "\n",
        "2.1 Write the WLS objective.\n",
        "\n",
        "2.2. Derive the WLS solution $\\hat{\\beta}$ under the above objective. Show step by step.\n",
        "\n",
        "2.3. Re-write the objective using a likelihood formulation assuming $ɛ \\sim N(0, D)$.\n",
        "\n",
        "2.4 Derive the OLS solution $\\hat{\\beta}_{MLE}$ using the above objective. Show step by step.\n",
        "\n",
        "2.5 Using [lineax](https://docs.kidger.site/lineax/), implement a solver for WLS."
      ],
      "metadata": {
        "id": "4sbheXNtiYy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lineax as lx\n",
        "\n",
        "from jax import Array\n",
        "from jax.typing import ArrayLike\n",
        "\n",
        "\n",
        "def solve_wls(y: ArrayLike, X: ArrayLike, D: ArrayLike) -> Array:\n",
        "  \"\"\"\n",
        "  Solves weighted least squares using lineax.\n",
        "\n",
        "  y: ArrayLike of observations\n",
        "  X: ArrayLike of covariates\n",
        "  D: ArrayLike of weights per observation\n",
        "\n",
        "  returns: $\\hat{\\beta}$ for WLS\n",
        "  \"\"\"\n",
        "  w = 1.0 / jnp.sqrt(D)\n",
        "\n",
        "  Xop = lx.MatrixLinearOperator(X)\n",
        "  Wop = lx.DiagonalLinearOperator(w)\n",
        "\n",
        "  # Whitened system: y* = W y, X* = W X\n",
        "  y_star = Wop.mv(y)\n",
        "  X_star = Wop @ Xop\n",
        "\n",
        "  sol = lx.linear_solve(\n",
        "      X_star,\n",
        "      y_star,\n",
        "      solver=lx.Normal(lx.CG(atol=1e-6, rtol=1e-6))\n",
        "  )\n",
        "  return sol.value"
      ],
      "metadata": {
        "id": "HELjji9HjffX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. MLE for scalar Poisson observations\n",
        "Given $x_1, \\dotsc, x_n$, assume that $x_i \\sim \\text{Poi}(\\lambda)$ for $i=1,\\dotsc,n$ where $\\text{Poi}(\\lambda)$ is the Poisson distribution with rate $\\lambda$.\n",
        "\n",
        "3.1 Write a likelihood-based formulation of the objective.\n",
        "\n",
        "3.2 Derive the MLE for the above objective. Show step by step.\n",
        "\n",
        "3.3 Implement a function that simulates Poisson distributed data with rate $\\lambda$ using JAX.\n",
        "\n",
        "3.4 Implement a function that computes the MLE $\\hat{\\lambda}$ given observations $x_1, \\dotsc, x_n$."
      ],
      "metadata": {
        "id": "VXwMNL3fkDsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lineax as lx\n",
        "import jax.random as rdm\n",
        "\n",
        "from jax import Array\n",
        "from jax.typing import ArrayLike\n",
        "\n",
        "\n",
        "def simulate_poisson(key, rate: ArrayLike, n: int) -> Array:\n",
        "  \"\"\"\n",
        "  Simulates Poisson distributed data.\n",
        "\n",
        "  key: PRNGKey to generate\n",
        "  rate: rate specifying the Poisson distribution; can be either a scalar, or\n",
        "    ArrayLike (i.e. unique to each observation)\n",
        "  n: the number of samples to generate\n",
        "\n",
        "  returns: $x_i \\sim \\text{Poi}(\\lambda_i)$\n",
        "  \"\"\"\n",
        "  pass\n",
        "\n",
        "\n",
        "def fit_poisson(x: ArrayLike) -> float:\n",
        "  \"\"\"\n",
        "  Fits Poisson distributed data.\n",
        "\n",
        "  x: ArrayLike observations\n",
        "\n",
        "  returns: estimate of $\\lambda$.\n",
        "  \"\"\"\n",
        "  pass"
      ],
      "metadata": {
        "id": "LY1UCqDBlF7l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}